here lstm.py have code in numpy for stock market preiction used only numpy and pandas ,minmax scaler ,L1 for avoiding the over fitting 
adam.py file have adam optimizer basic code implementation modify it for requirements 

lstmclassifier.py -- it is using lstm(128)-lstm(64)-dense(1) with sigmoid have given results 

lstmclassifier.py -- dense(1) lstm(128,64)
--dropout used after lstm(128)-before lstm(64)
104/104 [==============================] - 2s 17ms/step - loss: 3.8938e-05 - ac>
26/26 [==============================] - 1s 5ms/step
ends at 828(line)
array([[0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],

lstmclassifier.py -lstm(128,64)-Dense(64,1)relu,sigmoid
--dropout after lstm(128)-lstm(64)
104/104 [==============================] - 1s 13ms/step - loss: 8.8352e-08 - ac>
26/26 [==============================] - 1s 5ms/step
ends near 1654(line)
array([[0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],


lstmclassifier.py -lstm(128,64)-Dense(128,1)-
--dropout after lstm(128)-lstm(64)
104/104 [==============================] - 2s 19ms/step - loss: 1.2340e-07 - ac>
26/26 [==============================] - 1s 4ms/step
ends at 2481(line)
array([[0.9999999],
       [0.9999999],
       [0.9999999],
       [0.9999999],
       [0.9999999],

lstmclassifier.py -- lstm(128)-lstm(64)-Dense(128)-Dense(1)
--when dropout used after bilstm(128)-before bilstm(64)
Epoch 10/10
104/104 [==============================] - 2s 19ms/step - loss: 2.8227e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4755e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 11ms/step
array([[0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],

lstmclassifier.py -- lstm(128)-lstm(64)-Dense(128)-Dense(1)
--when dropout used after bilstm(2) before Dense(128) gave 1 as pedict
104/104 [==============================] - 2s 17ms/step - loss: 8.9954e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6093e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 11ms/step
array([[1.        ],
       [0.99999994],
       [1.        ],
       [0.99999994],
       [1.        ],
       [1.        ],
       [1.        ],
       [0.99999994], 
--when dropout used after Dense(128) before Dense(1)
Epoch 10/10
104/104 [==============================] - 2s 20ms/step - loss: 4.1442e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9579e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 10ms/step
array([[0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],

lstmclassifier.py -- bilstm(64)-bilstm(32)-dense(32,1)
--when dropout afte bilstm(64)-before dense(32)
104/104 [==============================] - 1s 11ms/step - loss: 3.0997e-05 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.1927e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 4ms/step
array([[0.9999908 ],
       [0.9999908 ],
       [0.9999908 ],
       [0.9999908 ],
       [0.9999908 ],
       [0.9999908 ],
       [0.9999908 ],

lstmclassifier.py -- bilstm(64)-bilstm(32)-dense(64,1)
--when dropout is after bilstm(32)-before dense(64) 
104/104 [==============================] - 1s 11ms/step - loss: 1.2053e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7294e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 6ms/step
array([[0.99999964],
       [0.99999964],
       [0.99999964],
       [0.99999964],
       [0.99999964],
       [0.99999964],

lstmclassifier.py --bilstm(64,32)-dense(64,1)
--when no dropout is there
104/104 [==============================] - 2s 20ms/step - loss: 8.1582e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2742e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 4ms/step
array([[0.99999285],
       [0.99999285],
       [0.99999285],
       [0.99999285],
       [0.99999285],
       [0.99999285],
       [0.99999285],

lstmclassifier.py -- bi(128,64)--Dense(128,1)
--when no dropout there 
104/104 [==============================] - 2s 20ms/step - loss: 1.9051e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.7420e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 7ms/step
array([[0.9999983 ],
       [0.9999983 ],
       [0.9999983 ],
       [0.9999983 ],
       [0.9999983 ],
       [0.9999983 ],

lstmclassifier.py--bilsmt(128,64)-Dense(64,1)
--when dropout there
104/104 [==============================] - 2s 18ms/step - loss: 7.8444e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.2751e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 6ms/step
array([[0.9999927 ],
       [0.9999927 ],
       [0.9999927 ],
       [0.9999927 ],
       [0.9999927 ],
       [0.9999927 ],
 
lstmclassifier.py --bilstm(128,64)-Dense(64,128,1)
--when dropout before Dense(64)-after bilstm(64)
104/104 [==============================] - 4s 42ms/step - loss: 5.3132e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.8649e-07 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 5s 7ms/step
array([[0.9999997 ],
       [0.9999997 ],
       [0.9999997 ],
       [0.9999997 ],
       [0.9999997 ],

lstmclassifier.py--bilstm(128,64)-Dense(64,128,1)
--when dropout after dense(64) - before(128)
104/104 [==============================] - 2s 20ms/step - loss: 5.8585e-07 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 9.0565e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 6ms/step
array([[0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],

#### we are sgmoid has everywhere 
lstmclassifier.py -- bilstm(128,64)-Dense(64,128,1)
--when we have all sigmoid and dropout after dense(64) before-dense(128)
104/104 [==============================] - 2s 18ms/step - loss: 1.9285e-04 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.5900e-04 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 6ms/step
array([[0.99984103],
       [0.99984103],
       [0.99984103],
       [0.99984103],
       [0.99984103],
       [0.99984103],

#relu in dense(64)
lstmmclassifier.py -- bilstm(128,4)--dense(64,1)
Epoch 10/10
802/802 [==============================] - 7s 9ms/step - loss: 2.0789e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 7.3299e-09 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
115/115 [==============================] - 2s 5ms/step
[[1.]
 [1.]
 [1.]
 ...
 [1.]
 [1.]
 [1.]]

lstmmclassifier.py -- bilstm(128,64)--dense(128,1)
Epoch 10/10
802/802 [==============================] - 9s 11ms/step - loss: 2.5722e-09 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 8.8508e-10 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
115/115 [==============================] - 3s 3ms/step
[[1.]
 [1.]
 [1.]
 ...
 [1.]
 [1.]
 [1.]]
