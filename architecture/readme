here lstm.py have code in numpy for stock market preiction used only numpy and pandas ,minmax scaler ,L1 for avoiding the over fitting 
adam.py file have adam optimizer basic code implementation modify it for requirements 

lstmclassifier.py -- it is using lstm(128)-lstm(64)-dense(1) with sigmoid have given results 

lstmclassifier.py -- dense(1) lstm(128,64)
--dropout used after lstm(128)-before lstm(64)
104/104 [==============================] - 2s 17ms/step - loss: 3.8938e-05 - ac>
26/26 [==============================] - 1s 5ms/step
ends at 828(line)
array([[0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],
       [0.99996364],

lstmclassifier.py -lstm(128,64)-Dense(64,1)relu,sigmoid
--dropout after lstm(128)-lstm(64)
104/104 [==============================] - 1s 13ms/step - loss: 8.8352e-08 - ac>
26/26 [==============================] - 1s 5ms/step
ends near 1654(line)
array([[0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],
       [0.99999994],


lstmclassifier.py -lstm(128,64)-Dense(128,1)-
104/104 [==============================] - 2s 19ms/step - loss: 1.2340e-07 - ac>
26/26 [==============================] - 1s 4ms/step
ends at 2481(line)
array([[0.9999999],
       [0.9999999],
       [0.9999999],
       [0.9999999],
       [0.9999999],

lstmclassifier.py -- lstm(128)-lstm(64)-Dense(128)-Dense(1)
--when dropout used after bilstm(128)-before bilstm(64)
Epoch 10/10
104/104 [==============================] - 2s 19ms/step - loss: 2.8227e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 2.4755e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 11ms/step

array([[0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],
       [0.99999756],

lstmclassifier.py -- lstm(128)-lstm(64)-Dense(128)-Dense(1)
--when dropout used after bilstm(2) before Dense gave 1 as pedict
104/104 [==============================] - 2s 17ms/step - loss: 8.9954e-08 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.6093e-08 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 11ms/step

array([[1.        ],
       [0.99999994],
       [1.        ],
       [0.99999994],
       [1.        ],
       [1.        ],
       [1.        ],
       [0.99999994], 
--when dropout used after Dense(128) before Dense(1)
Epoch 10/10
104/104 [==============================] - 2s 20ms/step - loss: 4.1442e-06 - accuracy: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 1.9579e-06 - val_accuracy: 1.0000 - val_precision: 1.0000 - val_recall: 1.0000
26/26 [==============================] - 2s 10ms/step

array([[0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],
       [0.99999803],
